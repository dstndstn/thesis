

\section{Contributions}

The \an system applies the framework of geometric hashing to the
astronomical problem of automated astrometric calibration of images.  This
can be seen as an instance of object recognition in which the
individual objects to be recognized---stars and galaxies---are almost
completely indistinctive at the resolution of typical images.  The
geometric relationships between the objects, however, can be used to
build very distinctive features.  The problem is made easier by the
fact that the stars are very distant, so the viewpoint is essentially
fixed, and while the stars do move, their motions are small enough
that their geometric relationships change very little.  The problem is
difficult largely for its sheer scale: typical images cover
one-millionth of the surface area of the sky or less, and errors of
various types mean that stars are lost and gained in both the image
and the reference catalog of stars.


Chapters \ref{chap:techreport}, \ref{chap:verify} and
\ref{chap:kdtree} highlight the main aspects of the system: a
geometric feature-indexing method that is able to generate
hypothesized matches; a robust probabilistic scheme for testing these
hypotheses; and a data structure implementation that allows the whole
system to operate at a speed that is acceptable for it to be used as a
practical tool.


The specific contributions include the following:
\nonumberparagraphs
\begin{itemize}
\item The design of our
``quad'' geometric hash code, including the constraints that the
hashed stars be within the circle defined by the ``framing'' stars,
and the constraints that break the symmetries of the hash code;
\item The idea of using a \kdtree rather than a hash table to
store the geometric hash codes;
\item A justified probabilistic framework for the verification of
the hypotheses generated by the geometric hashing system, including
the use of Bayesian decision theory to set thresholds in a rational
way;
\item A method for constructing indices that tiles the sky uniformly
with geometric features but avoids over-reliance on any individual
star;
\item Extensive evaluation of the \an system, including a large-scale study using
the Sloan Digital Sky Survey, and studies using a variety of other
imagery to explore edge cases;
\item In particular, an evaluation of the performance of indices using
triangles, quadruples, and quintuples of stars; and
\item A time- and space-efficient implementation of the \kdtree data structure.
\end{itemize}
\numberparagraphs


\section{Future work}

\subsection{Tuning of the \an system}

While the \an system as presented here is successful at recognizing a
wide variety of astronomical images, and is reasonably fast, there are
several aspects of the system that could be tuned to improve overall
performance in practice.


As detailed in \chapref{chap:techreport}, when attempting to recognize
an image we simply build each valid quad (or triangle or quintuple)
using stars in the image, starting with the brightest stars.
Different strategies for ordering the quads we test could lead to
improved performance.  When an image contains a bright
``distractor''---an object that looks like a star but isn't a real
star---the system will typically build a very large number of quads
that include the distractor, none of which can possibly produce a
correct result.  Instead of building quads strictly based on
brightness ordering, we could choose to build only a limited number of
quads from any star or pair of stars (perhaps queueing these
``over-used'' stars for further examination later) in order to examine
more faint stars sooner.  Alternatively, we could sample quads from
the image in a probabilistic manner, taking into account the
brightness of each star and perhaps the number of times it has already
been sampled.


Typically, the \an system has several indices in which it must search
for matches to each quad in the image.  Currently, we simply proceed
in lock-step: for each quad, we search each index in series.  This is
an embarassingly parallel problem, so distributing the indices across
multiple processor cores (and multiple machines) would lead to
speedups.  More importantly, however, we suspect that it would be
beneficial not to proceed in lock-step but to split the indices by
angular scale and let the wide-angle indices examine more quads.
Since searching in wide-angle indices is fast, this would tend to
balance the amount of computational effort (rather than the number of
quads) applied to each scale.  More generally, the computational
effort could be distributed based on the (expected or measured)
properties of the images to be recognized, with the computation being
ordered so that the most successful indices are checked first.
Indeed, we could build relative sparse indices that could be checked
quickly to recognize ``easy'' images, and denser, slower indices to
recognize ``hard'' images.


Our experiments in \secref{sec:triquint} showed that for Sloan Digital
Sky Survey images, a quad-based index was faster than either a
triangle- or quintuple-based index.  We expect that the relative
speeds will changes as a function of image scale, and that at some
large rangular scale a triangle-based index will be faster.  We have
not measured this, partly because we lack a large uniform test set of
wide-angle images.  Similarly, we found that for SDSS images and a
quad-based index, using a voting scheme---waiting for multiple
agreeing hypotheses to accumulate before running the verification
process---was slower and very memory-intensive (since our
implementation stored every hypothesis).  With a triangle-based index,
a voting scheme could be beneficial, because many more false
hypotheses are generated, and a voting scheme is supposed to reduce
the number of times the relatively expensive verification procedure is
run.  In order to decrease the memory requirements, we could use a
light-weight voting scheme that stores only some summary information
such as the \emph{healpix} containing the image center; we would then
run the verification procedure on any new hypothesis whose image
center healpix (or any of its healpix neighbours) had already been hit
by a previous hypothesis.


In principle, decisions about which indices to use (triangles, quads,
or quints; or density of features), whether or not to use voting, the
number of votes required before running the verification procedure,
and other search parameters, could be chosen at run-time based on
their relative costs (in terms of CPU time or memory) and the
properties of the images to be recognized and the desired operating
characteristics (speed versus recognition rate, for example).  We
suspect that the optimal structural aspects of the search (which
indices to use, and whether or not to use voting) are determined
almost exclusively by the angular scale of the images to be
recognized, and can thus be optimized off-line.  Trading speed for
recognition rate, in contrast, can be achieved by, for example, using
indices containing fewer features, or decreasing the feature-space
matching distance.  Using a sparser index simply decreases the number
of potential matches for each image, but increases the search speed.
Decreasing the feature-space matching distance means that some true
matches will not be found because positional noise of the stars in the
image or index moves the feature further than the distance threshold
in feature space.  We have not investigated how to trade off between
these approaches so as to optimize the speed of the system at a given
target recognition rate, but it could be done by simulating the
positional errors of stars in the image and the differences in
brightness ordering between the image and index.


\subsection{Additions to the \an system for practical recognition of astronomical images}


The \an system described here is intended to be equally able to
recognize images from any part of the sky and of any scale, using only
the information contained in the image pixels.  In many settings,
however, the images to be recognized are not uniformly distributed,
and other information is available.  This section mentions a few
extensions to the system that could improve its speed or recognition
rate in such real-world settings.


We have focused on building a system that is equally able to recognize
images from any part of the sky, but the coverage of astronomical
imaging is highly non-uniform.  Among both amateur astrophotographers
and professional astronomers, images of specific astronomical objects
(such as Messier objects and NGC/IC galaxies) are far more common than
images of ``blank sky''.  Yet the USNO-B reference catalog often
contains errors in regions of the sky containing bright stars,
nebulosity, or high stellar density, so an index built from that
reference catalog will tend to perform \emph{worse} in the parts of
the sky that are most commonly imaged.  Building a specialized index
(using an appropriate reference catalog) that is able to recognize the
most commonly imaged regions of the sky would improve the overall
speed and recognition rate of the system.


A related problem is that the brightest stars in an image are often
poorly localized due to saturation, diffraction spikes, halos, and
bleeding of the CCD; our brightness-ordering heuristics should take
this into account, perhaps by preferring to build quads from stars
within a (scale- and location-dependent) range of brightnesses, rather
than simply preferring the brightest stars.


Our approach presumes that individual stars and unresolved galaxies
are completely indistinctive and cannot be used individually to recognize
images.  We therefore ignore the \emph{appearance} of astronomical
sources and focus on their relative \emph{geometry}.  Yet resolved
galaxies and nebulae are commonly imaged, and their appearances can be
quite distinctive, as indicated by the evocative names of the
Sombrero, Whale, Whirlpool, and Sunflower galaxies and the Horsehead,
Running Chicken, Helix, Cat's Paw, and Eagle nebulae.  Since resolved
galaxies and regions of nebulosity are often problematic both in
reference catalogs and for source extraction routines, a
pattern-recognition system that could recognize these astronomical
objects based on their \emph{appearance} would be a good complement to
the geometry-based approach of \an.


Currently, the \an web service uses a static set of indices.  Ideally,
however, it would \emph{learn} about the sky and constantly update its
reference catalog and indices based on the stars that it finds in the
images it encounters.  A system that did this would be able to achieve
some remarkable feats: it could \emph{patch} the USNO-B reference
catalog in regions where the catalog has flaws.  It could
\emph{deepen} the reference catalog, since many images contain stars
that do not appear in the catalog.  By building new indices from its
deeper reference catalog, it would be able to recognize narrow-field
images in regions that had been previously imaged many times.  In this
way, it could adapt to the non-uniform \emph{interest} of astronomers
in different regions of the sky.  For example, if the system had
access to all astronomical imaging, it would easily be able to
recognize the narrow-field images from the Hubble Space Telescope,
because every Hubble image is preceded by ground-based imaging.  How
exactly a system would update and maintain an astrometric reference
catalog based on a huge amount of imaging is a question on which we
have speculated, in vague terms, in our ``theory of everything'' paper
\cite{theoryofeverything}.


Many of the images submitted to the \an web service are produced by
consumer-grade digital cameras and contain EXIF (exchangeable image
file format) tags, which include meta-data about the image such as the
camera model, lens, focal length, exposure time, aperture, and date.
We currently ignore these meta-data, but they could be quite useful.
Given the focal length of the lens and the camera model (thus the
sensor geometry), we can compute the pixel scale (in arcseconds per
pixel), which makes recognition of the image easier.  Perhaps more
interestingly, we could build up statistics on the distortion patterns
of different lenses, and given a new image, apply the inverse
distortion before attempting to recognize the image.  Of course, we
should never completely trust the information in the EXIF headers, but
we could use it as a possibly-correct hint about the image.


%-pre-processing to detect sky
%Thus far, we have run the \an system in a passive mode: it waits for
%users to submit images, and it assumes that it is given images of the
%night sky.  We could instead crawl the web searching for astronomical
%images.  A 

% -extending beyond the optical: catalogs and test sets

% -improve tweak by optimizing the verification objective.

\subsection{Other kinds of calibration}


After recognizing (\ie, astrometrically calibrating) an image, we can
match stars in the image with stars in a reference catalog.  This
enables other kinds of calibration and meta-data creation.  For
example, we can estimate the photometric calibration and bandpass
filter of the image, or estimate the date the image was taken.


Automated photometric calibration and bandpass estimation proceeds by
matching stars in the image to stars in the reference catalog, and
finding the best-fitting parameters that allow us to convert between
``instrumental'' fluxes in the image and magnitudes in one or several
of the bands in the reference catalog.  If we find that a single band
in the reference catalog fits the image well, it is likely that the
bandpass filters of the reference catalog and the image are similar;
if more than one band in the reference catalog is required to yield a
satisfactory fit, then the bandpass of the image is likely different
than any of those in the reference catalog.


Astrometric dating---calibrating the date on which an image was
taken---proceeds by computing the positions of reference catalog stars
at a given date (using their tabulated proper motions) and finding the
date when they best match those of the image stars \cite{blinddate}.
Perhaps surprisingly, the distribution of proper motions of stars is
such that even over a time baseline of $50$ to $100$ years, enough of
the stars move little enough that we are still able to recognize the
images based on their relative positions, yet enough of the stars move
enough that their changes in position contain sufficient information
to constrain the date on which the image was taken.  For typical
historical photographic plates, the date on which the image was taken
is constrained to within a few years using this method.  By adding
photometric information about variable stars, and about transients
that might appear in the image (planets, comets, satellites), we could
fine-tune the date estimate to much greater precision.


% collections of images -- comet orbital parameter estimation


\subsection{Using heterogenous images for science}


The \an system makes a large amount of heterogeneous data readily
available for scientific investigation.  How can large collections of
images be analyzed to answer scientific questions?  This is a
surprisingly ill-explored research area in astronomy.  We have been
doing some early experiments building generative models of
astronomical images, and doing probabilistic inference in these
models, and we feel this is a very promising avenue for combining the
information in images with very different resolutions, sensitivities,
and bandpasses.  This is an exciting area for future work.


